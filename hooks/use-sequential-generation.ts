/**
 * Hook pour la g√©n√©ration TOUT EN // des m√©dias dans le canvas
 * 
 * ARCHITECTURE TOUT EN // :
 * 1. TOUTES les images primaires (personnages + d√©cors) lanc√©es SIMULTAN√âMENT
 * 2. D√®s qu'une primaire est pr√™te, ses variantes sont lanc√©es IMM√âDIATEMENT
 *    (pas d'attente que les autres primaires soient termin√©es)
 * 3. Une fois toutes les images termin√©es, populer les collections
 * 4. TOUTES les vid√©os lanc√©es EN PARALL√àLE
 */

import { useState, useCallback, useRef } from 'react';
import { useReactFlow } from '@xyflow/react';
import type { Node } from '@xyflow/react';
import { toast } from 'sonner';

export interface GenerationStep {
  id: string;
  type: 'image' | 'image-edit' | 'video' | 'collection' | 'dvr';
  status: 'pending' | 'generating' | 'done' | 'error';
  nodeId: string;
  label: string;
  error?: string;
  imageInfo?: {
    prompt: string;
    aspectRatio: string;
    isReference?: boolean;
    referenceNodeId?: string;
  };
  videoInfo?: {
    prompt: string;
    characterCollectionIds?: string[];
    locationCollectionId?: string;
    duration?: number;
  };
  collectionSourceIds?: string[];
}

export interface GenerationProgress {
  currentStep: number;
  totalSteps: number;
  currentPhase: 'primary_images' | 'variant_images' | 'collections' | 'videos' | 'dvr' | 'done';
  steps: GenerationStep[];
  isGenerating: boolean;
  activeGenerations: number;  // Nombre de g√©n√©rations en cours simultan√©ment
}

interface UseSequentialGenerationOptions {
  onComplete?: (summary: GenerationSummary) => void;
  onError?: (error: string) => void;
  videoCopies?: number;
  imageModel?: string;
  videoModel?: string;
}

export interface GenerationSummary {
  totalImages: number;
  totalVideos: number;
  totalCollections: number;
  sentToDVR: number;
  errors: string[];
  duration: number;
}

export function useSequentialGeneration(options: UseSequentialGenerationOptions = {}) {
  const {
    onComplete,
    onError,
    videoCopies = 4,
    // IDs R√âELS depuis models-registry.ts (source de v√©rit√©)
    imageModel = 'wavespeed/google/nano-banana-pro/text-to-image-ultra',
    videoModel = 'kwaivgi/kling-v2.5-turbo-pro/image-to-video',
  } = options;

  const { getNodes, setNodes, updateNodeData } = useReactFlow();
  const [progress, setProgress] = useState<GenerationProgress>({
    currentStep: 0,
    totalSteps: 0,
    currentPhase: 'primary_images',
    steps: [],
    isGenerating: false,
    activeGenerations: 0,
  });
  
  const abortRef = useRef(false);
  const startTimeRef = useRef<number>(0);
  const generatedImagesRef = useRef<Map<string, string>>(new Map()); // nodeId -> url

  // ========== UTILITAIRES ==========
  const delay = (ms: number) => new Promise(resolve => setTimeout(resolve, ms));

  const waitForNodeRender = async (nodeId: string, timeout = 60000): Promise<string | null> => {
    const startTime = Date.now();
    
    while (Date.now() - startTime < timeout) {
      if (abortRef.current) return null;
      
      const nodes = getNodes();
      const node = nodes.find(n => n.id === nodeId);
      
      // V√©rifier si le n≈ìud a une URL g√©n√©r√©e
      const url = node?.data?.generated?.url || node?.data?.url;
      if (url) {
        generatedImagesRef.current.set(nodeId, url);
        return url;
      }
      
      await delay(500);
    }
    
    return null;
  };

  const updateStep = (stepId: string, updates: Partial<GenerationStep>) => {
    setProgress(prev => ({
      ...prev,
      steps: prev.steps.map(s => s.id === stepId ? { ...s, ...updates } : s),
    }));
  };

  const incrementActiveGenerations = () => {
    setProgress(prev => ({ ...prev, activeGenerations: prev.activeGenerations + 1 }));
  };

  const decrementActiveGenerations = () => {
    setProgress(prev => ({ ...prev, activeGenerations: Math.max(0, prev.activeGenerations - 1) }));
  };

  const incrementCompletedSteps = () => {
    setProgress(prev => ({ ...prev, currentStep: prev.currentStep + 1 }));
  };

  // ========== G√âN√âRATION D'IMAGE TEXT-TO-IMAGE ==========
  const generateImageT2I = async (nodeId: string, prompt: string, aspectRatio: string): Promise<boolean> => {
    try {
      incrementActiveGenerations();
      
      const response = await fetch('/api/image/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          nodeId,
          prompt,
          model: imageModel,
          aspectRatio,
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('Erreur g√©n√©ration image:', errorText);
        toast.error(`‚ùå Image ${nodeId.substring(0, 8)}`, {
          description: errorText.substring(0, 200),
          duration: 60_000,
          closeButton: true,
        });
        return false;
      }

      // Attendre que l'image soit rendue dans le n≈ìud
      const url = await waitForNodeRender(nodeId);
      return url !== null;
    } catch (error: any) {
      console.error('Erreur g√©n√©ration image:', error);
      toast.error(`‚ùå Image ${nodeId.substring(0, 8)}`, {
        description: error?.message || String(error),
        duration: 60_000,
        closeButton: true,
      });
      return false;
    } finally {
      decrementActiveGenerations();
    }
  };

  // ========== G√âN√âRATION D'IMAGE EDIT (variantes) ==========
  // D√©river le mod√®le I2I depuis le mod√®le T2I
  // Source de v√©rit√©: models-registry.ts
  const getEditModel = (t2iModel: string): string => {
    // Mapping T2I ‚Üí I2I depuis models-registry.ts
    if (t2iModel.includes('nano-banana-pro') && t2iModel.includes('ultra')) {
      return 'wavespeed/google/nano-banana-pro/edit-ultra';
    }
    if (t2iModel.includes('nano-banana-pro')) {
      return 'wavespeed/google/nano-banana-pro/edit';
    }
    if (t2iModel.includes('nano-banana')) {
      return 'wavespeed/google/nano-banana/edit';
    }
    // Fallback: remplacer text-to-image par edit
    return t2iModel.replace('text-to-image-ultra', 'edit-ultra').replace('text-to-image', 'edit');
  };
  
  const generateImageEdit = async (
    nodeId: string, 
    prompt: string, 
    aspectRatio: string,
    referenceImageUrl: string
  ): Promise<boolean> => {
    try {
      incrementActiveGenerations();
      
      const editModel = getEditModel(imageModel);
      
      const response = await fetch('/api/image/edit', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          nodeId,
          prompt,
          model: editModel,
          aspectRatio,
          sourceImages: [referenceImageUrl],
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('Erreur g√©n√©ration image edit:', errorText);
        toast.error(`‚ùå Edit ${nodeId.substring(0, 8)}`, {
          description: errorText.substring(0, 200),
          duration: 60_000,
          closeButton: true,
        });
        return false;
      }

      // Attendre que l'image soit rendue dans le n≈ìud
      const url = await waitForNodeRender(nodeId);
      return url !== null;
    } catch (error: any) {
      console.error('Erreur g√©n√©ration image edit:', error);
      toast.error(`‚ùå Edit ${nodeId.substring(0, 8)}`, {
        description: error?.message || String(error),
        duration: 60_000,
        closeButton: true,
      });
      return false;
    } finally {
      decrementActiveGenerations();
    }
  };

  // ========== G√âN√âRATION DE VID√âO ==========
  const generateVideo = async (nodeId: string, prompt: string): Promise<boolean> => {
    try {
      incrementActiveGenerations();
      
      const response = await fetch('/api/video/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          nodeId,
          prompt,
          model: videoModel,
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('Erreur g√©n√©ration vid√©o:', errorText);
        toast.error(`‚ùå Vid√©o ${nodeId.substring(0, 8)}`, {
          description: `[${videoModel}] ${errorText.substring(0, 200)}`,
          duration: 60_000,
          closeButton: true,
        });
        return false;
      }

      // Attendre que la vid√©o soit rendue
      const url = await waitForNodeRender(nodeId, 180000); // 3 minutes pour les vid√©os
      return url !== null;
    } catch (error: any) {
      console.error('Erreur g√©n√©ration vid√©o:', error);
      toast.error(`‚ùå Vid√©o ${nodeId.substring(0, 8)}`, {
        description: `[${videoModel}] ${error?.message || String(error)}`,
        duration: 60_000,
        closeButton: true,
      });
      return false;
    } finally {
      decrementActiveGenerations();
    }
  };

  // ========== POPULATION DE COLLECTION ==========
  const populateCollection = async (
    collectionNodeId: string,
    sourceNodeIds: string[]
  ): Promise<boolean> => {
    try {
      const nodes = getNodes();
      const items: any[] = [];

      for (const sourceId of sourceNodeIds) {
        const sourceNode = nodes.find(n => n.id === sourceId);
        const url = sourceNode?.data?.generated?.url || sourceNode?.data?.url || generatedImagesRef.current.get(sourceId);
        
        if (url) {
          items.push({
            id: sourceId,
            type: 'image',
            enabled: true,
            url,
            width: sourceNode?.data?.generated?.width || sourceNode?.width,
            height: sourceNode?.data?.generated?.height || sourceNode?.height,
            name: sourceNode?.data?.label || 'Image',
          });
        }
      }

      if (items.length > 0) {
        updateNodeData(collectionNodeId, { items, collapsed: false });
        return true;
      }

      return false;
    } catch (error) {
      console.error('Erreur population collection:', error);
      return false;
    }
  };

  // ========== ENVOI √Ä DVR ==========
  const sendToDVR = async (nodeId: string): Promise<boolean> => {
    try {
      const nodes = getNodes();
      const node = nodes.find(n => n.id === nodeId);
      
      if (!node?.data?.generated?.url && !node?.data?.url) {
        return false;
      }

      const response = await fetch('/api/davinci-resolve', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          action: 'import',
          url: node.data.generated?.url || node.data.url,
          name: node.data.label || 'Media',
        }),
      });

      return response.ok;
    } catch (error) {
      console.error('Erreur envoi DVR:', error);
      return false;
    }
  };

  // ========== G√âN√âRATION PARALL√àLE PRINCIPALE ==========
  const startGeneration = useCallback(async (
    characterImageNodes: { 
      characterId: string; 
      imageNodeIds: string[];
      prompts: Record<string, string>;
      aspectRatios: Record<string, string>;
      order: string[];
      generationTypes?: Record<string, string>;
      primaryNodeId?: string;
    }[],
    locationImageNodes: { 
      locationId: string; 
      imageNodeIds: string[];
      prompts: Record<string, string>;
      aspectRatios: Record<string, string>;
      order: string[];
      generationTypes?: Record<string, string>;
      primaryNodeId?: string;
    }[],
    characterCollections: [string, string][],
    locationCollections: [string, string][],
    videoNodes: { 
      planId: string; 
      videoNodeIds: string[];
      prompt: string;
      characterCollectionIds?: string[];
      locationCollectionId?: string;
    }[],
    sendToDVRAfter: boolean = false,
    videoSettings?: { duration: number; aspectRatio: string }
  ) => {
    if (progress.isGenerating) {
      toast.error('Une g√©n√©ration est d√©j√† en cours');
      return;
    }

    abortRef.current = false;
    startTimeRef.current = Date.now();
    generatedImagesRef.current.clear();

    // Pr√©parer les √©tapes
    const steps: GenerationStep[] = [];
    const nodes = getNodes();
    
    // Collecter toutes les t√¢ches d'images primaires
    const primaryImageTasks: { 
      stepId: string; 
      nodeId: string; 
      prompt: string; 
      aspectRatio: string;
      entityType: 'character' | 'location';
      entityId: string;
    }[] = [];
    
    // Collecter toutes les t√¢ches de variantes (seront lanc√©es apr√®s leur primaire)
    const variantImageTasks: Map<string, {
      stepId: string;
      nodeId: string;
      prompt: string;
      aspectRatio: string;
      referenceNodeId: string;
    }[]> = new Map();

    // Images personnages
    for (const charData of characterImageNodes) {
      const order = charData.order || ['primary', 'face', 'profile', 'back'];
      const nodeIdsByView: Record<string, string> = {};
      
      for (let i = 0; i < order.length; i++) {
        const viewType = order[i];
        if (charData.imageNodeIds[i]) {
          nodeIdsByView[viewType] = charData.imageNodeIds[i];
        }
      }

      for (let i = 0; i < order.length; i++) {
        const viewType = order[i];
        const nodeId = nodeIdsByView[viewType];
        if (!nodeId) continue;

        const isReference = i === 0;
        const stepId = isReference ? `img-t2i-${nodeId}` : `img-edit-${nodeId}`;
        const prompt = charData.prompts[viewType] || '';
        const aspectRatio = charData.aspectRatios[viewType] || '1:1';

        steps.push({
          id: stepId,
          type: isReference ? 'image' : 'image-edit',
          status: 'pending',
          nodeId,
          label: isReference ? `üé® ${viewType} (r√©f√©rence)` : `‚úèÔ∏è ${viewType} (variante)`,
          imageInfo: {
            prompt,
            aspectRatio,
            isReference,
            referenceNodeId: isReference ? undefined : nodeIdsByView[order[0]],
          },
        });

        if (isReference) {
          primaryImageTasks.push({
            stepId,
            nodeId,
            prompt,
            aspectRatio,
            entityType: 'character',
            entityId: charData.characterId,
          });
        } else {
          const primaryNodeId = charData.primaryNodeId || nodeIdsByView[order[0]];
          if (!variantImageTasks.has(primaryNodeId)) {
            variantImageTasks.set(primaryNodeId, []);
          }
          variantImageTasks.get(primaryNodeId)!.push({
            stepId,
            nodeId,
            prompt,
            aspectRatio,
            referenceNodeId: primaryNodeId,
          });
        }
      }
    }

    // Images d√©cors/lieux
    for (const locData of locationImageNodes) {
      const order = locData.order || ['primary', 'angle2', 'plongee', 'contrePlongee'];
      const nodeIdsByView: Record<string, string> = {};
      
      for (let i = 0; i < order.length; i++) {
        const viewType = order[i];
        if (locData.imageNodeIds[i]) {
          nodeIdsByView[viewType] = locData.imageNodeIds[i];
        }
      }

      for (let i = 0; i < order.length; i++) {
        const viewType = order[i];
        const nodeId = nodeIdsByView[viewType];
        if (!nodeId) continue;

        const isReference = i === 0;
        const stepId = isReference ? `img-t2i-${nodeId}` : `img-edit-${nodeId}`;
        const prompt = locData.prompts[viewType] || '';
        const aspectRatio = locData.aspectRatios[viewType] || '16:9';

        steps.push({
          id: stepId,
          type: isReference ? 'image' : 'image-edit',
          status: 'pending',
          nodeId,
          label: isReference ? `üé® ${viewType} (r√©f√©rence)` : `‚úèÔ∏è ${viewType} (variante)`,
          imageInfo: {
            prompt,
            aspectRatio,
            isReference,
            referenceNodeId: isReference ? undefined : nodeIdsByView[order[0]],
          },
        });

        if (isReference) {
          primaryImageTasks.push({
            stepId,
            nodeId,
            prompt,
            aspectRatio,
            entityType: 'location',
            entityId: locData.locationId,
          });
        } else {
          const primaryNodeId = locData.primaryNodeId || nodeIdsByView[order[0]];
          if (!variantImageTasks.has(primaryNodeId)) {
            variantImageTasks.set(primaryNodeId, []);
          }
          variantImageTasks.get(primaryNodeId)!.push({
            stepId,
            nodeId,
            prompt,
            aspectRatio,
            referenceNodeId: primaryNodeId,
          });
        }
      }
    }

    // Collections personnages
    for (const [charId, collectionId] of characterCollections) {
      const charData = characterImageNodes.find(c => c.characterId === charId);
      steps.push({
        id: `coll-${collectionId}`,
        type: 'collection',
        status: 'pending',
        nodeId: collectionId,
        label: `üìÅ Collection perso`,
        collectionSourceIds: charData?.imageNodeIds || [],
      });
    }

    // Collections d√©cors
    for (const [locId, collectionId] of locationCollections) {
      const locData = locationImageNodes.find(l => l.locationId === locId);
      steps.push({
        id: `coll-${collectionId}`,
        type: 'collection',
        status: 'pending',
        nodeId: collectionId,
        label: `üìÅ Collection d√©cor`,
        collectionSourceIds: locData?.imageNodeIds || [],
      });
    }

    // Vid√©os
    for (const videoData of videoNodes) {
      for (let copyIdx = 0; copyIdx < videoData.videoNodeIds.length; copyIdx++) {
        const videoNodeId = videoData.videoNodeIds[copyIdx];
        steps.push({
          id: `video-${videoNodeId}`,
          type: 'video',
          status: 'pending',
          nodeId: videoNodeId,
          label: `üé¨ Vid√©o ${copyIdx + 1}`,
          videoInfo: {
            prompt: videoData.prompt || '',
            characterCollectionIds: videoData.characterCollectionIds,
            locationCollectionId: videoData.locationCollectionId,
            duration: videoSettings?.duration,
          },
        });

        if (sendToDVRAfter) {
          steps.push({
            id: `dvr-${videoNodeId}`,
            type: 'dvr',
            status: 'pending',
            nodeId: videoNodeId,
            label: `üì§ DVR`,
          });
        }
      }
    }

    setProgress({
      currentStep: 0,
      totalSteps: steps.length,
      currentPhase: 'primary_images',
      steps,
      isGenerating: true,
      activeGenerations: 0,
    });

    const summary: GenerationSummary = {
      totalImages: 0,
      totalVideos: 0,
      totalCollections: 0,
      sentToDVR: 0,
      errors: [],
      duration: 0,
    };

    try {
      // ========== TOUT EN // : PRIMAIRES + VARIANTES ==========
      const totalImageTasks = primaryImageTasks.length + Array.from(variantImageTasks.values()).flat().length;
      setProgress(prev => ({ ...prev, currentPhase: 'primary_images' }));
      toast.info(`üöÄ TOUT EN // : ${totalImageTasks} images lanc√©es SIMULTAN√âMENT`);
      console.log(`[ParallelGen] TOUT EN // : ${primaryImageTasks.length} primaires + variantes`);

      // Lancer TOUTES les primaires, chacune lance ses variantes imm√©diatement
      const allImagePromises = primaryImageTasks.map(async (task) => {
        if (abortRef.current) return { task, success: false };

        updateStep(task.stepId, { status: 'generating' });

        const success = await generateImageT2I(task.nodeId, task.prompt, task.aspectRatio);

        if (success) {
          updateStep(task.stepId, { status: 'done' });
          summary.totalImages++;
          incrementCompletedSteps();

          // IMM√âDIATEMENT lancer les variantes EN PARALL√àLE
          const variants = variantImageTasks.get(task.nodeId);
          if (variants && variants.length > 0) {
            const referenceUrl = generatedImagesRef.current.get(task.nodeId);
            if (referenceUrl) {
              console.log(`[ParallelGen] üöÄ ${variants.length} variantes pour ${task.nodeId} lanc√©es EN //`);
              
              const variantPromises = variants.map(async (variant) => {
                if (abortRef.current) return false;

                updateStep(variant.stepId, { status: 'generating' });

                const variantSuccess = await generateImageEdit(
                  variant.nodeId,
                  variant.prompt,
                  variant.aspectRatio,
                  referenceUrl
                );

                if (variantSuccess) {
                  updateStep(variant.stepId, { status: 'done' });
                  summary.totalImages++;
                  incrementCompletedSteps();
                } else {
                  updateStep(variant.stepId, { status: 'error', error: '√âchec g√©n√©ration' });
                  summary.errors.push(`Variante ${variant.nodeId}`);
                  incrementCompletedSteps();
                }

                return variantSuccess;
              });

              await Promise.all(variantPromises);
            }
          }
        } else {
          updateStep(task.stepId, { status: 'error', error: '√âchec g√©n√©ration' });
          summary.errors.push(`Primaire ${task.nodeId}`);
          incrementCompletedSteps();
        }

        return { task, success };
      });

      // Attendre que TOUT soit termin√©
      await Promise.all(allImagePromises);

      if (abortRef.current) throw new Error('G√©n√©ration annul√©e');

      // ========== PHASE 2 : COLLECTIONS ==========
      setProgress(prev => ({ ...prev, currentPhase: 'collections' }));
      toast.info('üìÅ Cr√©ation des collections...');

      for (const step of steps.filter(s => s.type === 'collection')) {
        if (abortRef.current) break;

        updateStep(step.id, { status: 'generating' });
        
        const success = await populateCollection(step.nodeId, step.collectionSourceIds || []);

        if (success) {
          updateStep(step.id, { status: 'done' });
          summary.totalCollections++;
        } else {
          updateStep(step.id, { status: 'error', error: 'Collection vide' });
        }
        incrementCompletedSteps();
      }

      // ========== PHASE 3 : TOUTES LES VID√âOS EN PARALL√àLE ==========
      const videoSteps = steps.filter(s => s.type === 'video');
      if (videoSteps.length > 0) {
        setProgress(prev => ({ ...prev, currentPhase: 'videos' }));
        toast.info(`üé¨ Lancement de ${videoSteps.length} vid√©os EN PARALL√àLE...`);
        console.log(`[ParallelGen] Phase 3: ${videoSteps.length} vid√©os EN PARALL√àLE`);

        // Lancer TOUTES les vid√©os SIMULTAN√âMENT
        const videoPromises = videoSteps.map(async (step) => {
          if (abortRef.current) return false;

          updateStep(step.id, { status: 'generating' });

          const success = await generateVideo(step.nodeId, step.videoInfo?.prompt || '');

          if (success) {
            updateStep(step.id, { status: 'done' });
            summary.totalVideos++;

            // Envoyer √† DVR si activ√©
            if (sendToDVRAfter) {
              const dvrStepId = `dvr-${step.nodeId}`;
              updateStep(dvrStepId, { status: 'generating' });

              const dvrSuccess = await sendToDVR(step.nodeId);

              if (dvrSuccess) {
                updateStep(dvrStepId, { status: 'done' });
                summary.sentToDVR++;
              } else {
                updateStep(dvrStepId, { status: 'error', error: '√âchec DVR' });
              }
            }
          } else {
            updateStep(step.id, { status: 'error', error: '√âchec g√©n√©ration' });
            summary.errors.push(`Vid√©o ${step.nodeId}`);
          }

          incrementCompletedSteps();
          return success;
        });

        await Promise.all(videoPromises);
      }

      // ========== TERMIN√â ==========
      summary.duration = Date.now() - startTimeRef.current;
      
      setProgress(prev => ({ ...prev, currentPhase: 'done', isGenerating: false, activeGenerations: 0 }));

      // Toast de r√©sum√©
      const toastMessage = `
üéâ G√©n√©ration PARALL√àLE termin√©e !

üìä R√©sum√© :
‚Ä¢ ${summary.totalImages} images g√©n√©r√©es
‚Ä¢ ${summary.totalCollections} collections cr√©√©es
‚Ä¢ ${summary.totalVideos} vid√©os g√©n√©r√©es
‚Ä¢ ${summary.sentToDVR} envoy√©es √† DVR
‚Ä¢ ${summary.errors.length} erreurs
‚Ä¢ Dur√©e : ${Math.round(summary.duration / 1000)}s
      `.trim();

      toast.success(toastMessage, { duration: 10000 });

      onComplete?.(summary);
    } catch (error: any) {
      console.error('Erreur g√©n√©ration parall√®le:', error);
      setProgress(prev => ({ ...prev, isGenerating: false, activeGenerations: 0 }));
      
      // Afficher l'erreur compl√®te avec dur√©e de 1 minute
      toast.error('‚ùå Erreur g√©n√©ration', {
        description: error.message,
        duration: 60_000,
        closeButton: true,
      });
      
      onError?.(error.message);
    }
  }, [progress.isGenerating, getNodes, updateNodeData, videoCopies, imageModel, videoModel, onComplete, onError]);

  // ========== ANNULER ==========
  const cancelGeneration = useCallback(() => {
    abortRef.current = true;
    setProgress(prev => ({ ...prev, isGenerating: false, activeGenerations: 0 }));
    toast.warning('G√©n√©ration annul√©e');
  }, []);

  return {
    progress,
    startGeneration,
    cancelGeneration,
  };
}
